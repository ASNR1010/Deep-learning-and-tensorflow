{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=['hello my name is chandan how r u ','Hello ,win money ,win from me','Call me hello,call me tomorrow','Welcome India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello my name is chandan how r u ',\n",
       " 'Hello ,win money ,win from me',\n",
       " 'Call me hello,call me tomorrow',\n",
       " 'Welcome India']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello my name is chandan how r u ', 'hello ,win money ,win from me', 'call me hello,call me tomorrow', 'welcome india']\n"
     ]
    }
   ],
   "source": [
    "small_doc=[]\n",
    "for i in doc:\n",
    "    small_doc.append(i.lower())\n",
    "print(small_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello my name is chandan how r u ', 'hello win money win from me', 'call me hellocall me tomorrow', 'welcome india']\n"
     ]
    }
   ],
   "source": [
    "#remove punctuation\n",
    "doc_pun=[]\n",
    "import string\n",
    "for i in small_doc:\n",
    "    doc_pun.append(i.translate(str.maketrans('','',string.punctuation)))\n",
    "print(doc_pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hello', 'my', 'name', 'is', 'chandan', 'how', 'r', 'u', ''], ['hello', 'win', 'money', 'win', 'from', 'me'], ['call', 'me', 'hellocall', 'me', 'tomorrow'], ['welcome', 'india']]\n"
     ]
    }
   ],
   "source": [
    "# every token is splitted as individual entry\n",
    "doc_new=[]\n",
    "for i in doc_pun:\n",
    "    doc_new.append(i.split(' '))\n",
    "print(doc_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'hello': 1,\n",
      "          'my': 1,\n",
      "          'name': 1,\n",
      "          'is': 1,\n",
      "          'chandan': 1,\n",
      "          'how': 1,\n",
      "          'r': 1,\n",
      "          'u': 1,\n",
      "          '': 1}),\n",
      " Counter({'win': 2, 'hello': 1, 'money': 1, 'from': 1, 'me': 1}),\n",
      " Counter({'me': 2, 'call': 1, 'hellocall': 1, 'tomorrow': 1}),\n",
      " Counter({'welcome': 1, 'india': 1})]\n"
     ]
    }
   ],
   "source": [
    "# checking each sample and count token in particular sample\n",
    "word_list=[]\n",
    "import pprint #used for text\n",
    "from collections import Counter\n",
    "for i in doc_new:\n",
    "    word_list.append(Counter(i))\n",
    "pprint.pprint(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect=CountVectorizer()\n",
    "count_vect.fit(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'chandan',\n",
       " 'from',\n",
       " 'hello',\n",
       " 'how',\n",
       " 'india',\n",
       " 'is',\n",
       " 'me',\n",
       " 'money',\n",
       " 'my',\n",
       " 'name',\n",
       " 'tomorrow',\n",
       " 'welcome',\n",
       " 'win']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the feature names\n",
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2],\n",
       "       [2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydoc_array=count_vect.transform(doc).toarray()\n",
    "mydoc_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
